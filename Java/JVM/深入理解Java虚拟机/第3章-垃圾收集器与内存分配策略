### 3.2 判断对象可回收的几种方式以及适用场景，尽量举例论证说明
  引用计数实现简单，使用效率高，只是简单的判断一下计数器是否等于0就可判定对象是否要回收，但缺点是对于循环引用无可奈何，而引用链的方式则正好想法。
  [补充] 分析一下常用中间件都是用什么方式判断「对象已死？」
   Java：因为Java支持循环引用的写法，因此只能使用引用链方式判定；
   Redis：Redis对象比较简单，不存在对象套对象的写法，因此采用了引用计数方式，在一个key过期被从redis实例中踢除时，还需判断对应的value是否还有其他key共享。
   Memcache：memcache不会释放内存，而是重新利用。假如当key过期时memcache并不会直接释放掉段内存，而是当有需要同等大小的请求时，直接将过期的值覆盖，然后复用这段空间。
   MongoDB/MySQL：网上资料比较少，个人推断虽然这两者也是作为存储组件存在，但数据更多的是写在磁盘上，因此好像对于value不敏感。

### 3.3 垃圾收集算法有哪些，分别用于哪些场景，尽量举例论证说明

### 3.4 HotSpot算法细节
#### 3.4.1 根节点枚举
 1.在GC根节点枚举时为什么一定要StopWorld？
   如书中所言，是为了保证GC时准确性，猜测如果这个环节GC线程和用户线程并行，可能会导致被GC线程标记为回收的对象，因为用户线程原因而再次引用导致被误GC。
 2.为什么需要OopMap，GC时直接线程堆栈中栈帧内的局部变量作为GC-Root去遍历有什么问题吗？会很慢吗，为什么要引用OopMap。
   因为HotSpot虚拟机采用了「准确式垃圾收集」方式，所以JVM必须单独有一个地方存储了哪些地方存储了对象引用。如果采用「保守式垃圾收集」直接从GC-Roots遍历，仅在栈中识别指针和非指针比较耗费成本。
   JVM如何判断数据是引用还是基本数据参考这篇文章：https://blog.csdn.net/Leeycw96/article/details/90704760
 3.OopMap中存的是什么数据，内部存储结构是什么样的？
   OopMap用于保存正在执行线程中引用与对象的关系。换句话说就是记录了当前线程栈中的引用类型的局部变量，以及对应引用了堆中的对象的关系。通过OopMap能够快速检索出引用类型变量。
 4.GC-Root区分新生代和老年代吗，如果只出发MirorGC，从GC-ROOT搜索怎么避开搜索老年代？

#### 3.4.2 安全点
 什么是安全点: 为了配合OopMap进行GC，只在特定的位置记录了GCRoot枚举，这些位置就是安全点，一般选取位置就是循环跳转，方法调用等地方。
 为什么要使用安全点: 因为在程序运行过程中，需要记录引用和对象的关系
 安全点是如何配合OopMap工作的:

#### 3.4.3 安全区域
 1.

<<<<<<< HEAD
### 3.5
=======
#### 3.4.4 卡表和记忆集
 1.卡表和记忆集的关系
   卡表是记忆集的一种实现。
 2.卡表解决了什么问题？为什么要用卡表
   为了解决在minorgc时，避免全量扫描老年代。举个例子，minorgc时，新生代中存在一个A对象，且新生代中的任意一个对象都没有指向对象A，但此时不能冒然将A标记为垃圾对象，因为无法排出是否有老年代对象引用了它。
   为了解决这个问题，JVM不可能全量扫描老年代的所有对象，那样开销太大了，毕竟minorgc就是一个比较轻的操作。所以hotspot使用了卡表这种实现在minorgc时避免了对老年代全量扫描。
 3.HotSpot是如何通过卡表避免全表扫描的？
   hotspot将老年代分成一块一块512字节大小的区域（512就是一个固定值，至于为什么是这个数字，推测应该就是个经验值），然后创建一个byte数组来与之映射。例如老年代有1G大小，根据规定每个region大小是512字节，
   那么1G除以512就有2M个Region，于是hotspot就创建了一个长度为2M的byte类型数组与之对应，然后通过数组下标加老年代起始位置偏移量来推算出实际内存地址，数组值记录了对应的Region是否存在引用新生代对象。这样
   形成了一个映射关系，在minorgc时就作为了一组新的gc-root，判断数组值为true对应的Region就是要进行GC的区域。

#### 3.4.5 写屏障
  what：对比Spring的AOP，我理解就是对Java对象中写操作的切面拦截。
  why：写屏障的目的为了解决「即时编译」后对机器指令进行拦截，将对象赋值动作关联到卡表。
       如果只是解释执行字节码而言，虚拟机是完全有介入拦截写操作的空间的；但在JIT场景中，经过编译的JVM字节码已经变成了更加底层的机器指令，此时就必须找到一个在机器码层面的手段，来拦截到对象的赋值操作，写屏障就是完成这个使命的一种手段。
  how：虚拟机会通过词法分析，为所有赋值操作都生成一个写屏障指令，被写屏障拦截到的赋值操作，都会直接更新对应的CardTable。
       关于更多写屏障介绍以及源码分析，可以参考一个日本人写的《JVM G1GC的算法与实现》一书（比较深入，看不太懂）
【补充】写屏障的伪共享问题
    假如CPU的CacheLine时64字节，而一个卡表元素时1字节，64个元素共用一个缓存行，而64个元素大概对应32K内存（64*512），因此多个线程在这32K内的区域并发更新时，就会因为并发写入而影响性能（参考MESI回写失效）。
    解决这个问题可以启用JVM参数：-XX:+UseCondCardMark参数来在写前判断，但额外的判断也存在性能损耗（个人觉得这个参数很难把握，而且网上相关资料也不多，慎用吧）

#### 3.4.6 并发可达性分析
  How：并发可达性分析工作过程
   a) 从GC-Root开始遍历进行可达性分析，采用3色（黑白灰）标记法来最判定对象存活还是死亡
      I.黑色：存活对象，标记完应该保留
      II.白色：死亡对象，标记完应该被回收掉
      III.灰色：个人理解就是正在判定的对象（书中原文是表示被GC访问过，但这个对象上至少存在一个引用没有被扫描过）
     【问题】为什么需要灰色呢？直接用黑白有问题吗？
   b) 初始状态所有节点均是白色，即死亡状态
   c) 根据对象的引用关系，一直遍历下去，可达对象均标记为黑色。
     【问题】黑白灰记哪呢？对象的MarkWord里好像没有地方可以记啊
 【问题1】在分析可达对象时，GC线程与用户线程并行时会遇到什么问题？针对问题又有什么解决方案？
   a) 销毁对象被重新标记为存活：这种漏标的浮动垃圾如果只是少量影响不大，可以容忍。如果漏标太多那说明访问的这段内存属于热点数据，最好就加内存，加机器解决问题吧
   b) 存活对象被标记为销毁：相对第一点，这个问题是比较致命的，但JVM不同的GC方式分别提供了2个解决方案
     I.增量更新：通过「写后屏障」记录增量修改数据，然后等并发扫描结束后，再重新扫描一次增量修改的数据即可。
      【思考】重新扫描增量更新节点时，是不是依旧会与用户线程并发，导致数据错误？
             理论上会存在这个可能，但扫描增量更新节点时，被用户线程修改的数据应该会再次被标记为增量更新，因此数据时不会发生错误的。
     II.原始快照：通过「写前屏障」记录即将被删除的引用关系，等并发扫描之后再重新扫描一次数据即可。

### 3.5 这节除了了G1以外几乎都知道，但需要注重整理一下，个别GC已经弄混了

>>>>>>> 8a7ff09a54edab2cc94c5a1d9b3a09b09e46f9da
#### 3.5.6 CMS收集器
 CMS收集器工作目的：
   垃圾收集时，更为关注系统的响应速度，减少GC停顿时间为主。
 CMS收集器工作原理：
   1.初始标记，标记出GC-Root直接关联的对象，该步骤是Stop-World操作
   2.并发标记，根据初始标记的对象遍历标记所有引用的对象，该步骤GC线程与用户线程并行
   3.重新标记，修正并发标记期间，用户线程增量变更产生的影响
   4.并发清除
 CMS收集器工作过程：
   1.线程运行时设置OopMap
   2.当需要GC时，所有执行中的线程必须跑到SafePoint然后中断
   3.不在执行中的线程(处于Block或Sleep状态)处于SafeRegion
   4.遍历OopMap，根据可达性分析，区分标记出存活对象与垃圾对象
   5.然后根据区域和具体GC实现进行清除、复制、整理算法
   6.如果GC过程中，有Sleep的线程醒来，由于在SafeRegion也需要等待GC线程执行完。

【问题】
  1.CMS收集器为什么要进行3次标记操作
    a) 第一次标记是线性标记，根据GCRoot找出直接引用
    b) 第二次标记是图状标记，根据第一次标记延伸找出间接引用
    c) 第三次标记属于针对第二步并发期间，对增量数据的标记，为了避免引用对象被回收的问题。
  2.CMS收集器第一次和第三次标记操作为什么要设计成STW，如果和用户线程并行有什么问题吗？
   	a) 第一次初始标记一定要设计成STW，主要是为了避免用户线程和GC线程在读写ThreadStack时并发问题。假设第一次标记不进行STW，由于用户线程处于执行中，
       导致每个线程的ThreadStack不断进行入栈出栈，其实就是GC-ROOT在不断的发生变化，而此时GC线程需要读取GC-ROOT，除非ThreadStack被设计成线程安
       全的Stack，否则并发读写将出现不可预见的问题。进一步思考，将ThreadStack设计成线程安全的对象，还不如直接在第一次标记时STW，让GC单线程处理。
   	b) 第三次标记STW原因：因为在第二次并发标记时，由于用户线程的改变引用可能导致存在漏掉垃圾或引用消失问题，因此基于第三次标记要重新STW，来保证GC正确性。
  3.CMS回收过程中，最耗时的是那个环节的操作？
    a) 并发标记: 如果说第一次标记GCRoot是线性遍历，那么并发标记就是基于GCRoot产生的图状遍历。
    b) 并发清除: 
  4.在并发标记阶段，CMS收集器是如何避免GC线程回收有效引用的？
    使用增量更新的方式，当黑色引用指向白色引用时，将其记录为增量数据，待并发扫描结束后，再将黑色节点重新扫描。
     a) 正常情况下黑色节点不会直接指向白色节点，往往是灰色或黑色。
     b) 黑色节点代表扫描过的节点，再次进行扫描往往都是因为增量数据导致的。
  5.CMS的缺点：
     a) 对CPU资源敏感，当处理器核心数量不足4时，GC线程对用户线程影响比较明显。
     b) 因为CMS采用标记清除算法，所以GC完后会有浮动垃圾；
     c) 且在CMS运行期间，如果预留内存无法满足程序新分配对象的需求，则会出现「并发失败」，则启用SerialOld重新一次GC。
       【思考】「并发失败」后的GC会Stop World，为什么不采用ParOld而是采用SerialOld，猜测应该是GC架构遗留问题导致。之前看过之所以几个GC引擎无法兼容，是因为框架导致。
  
#### G1
 1.线上G1配置参数？一般分了多少个Region、每次停顿多长时间？
 2.我理解G1不是没有新生代了吗，怎么还有younggc或fullgc
   G1没有固定的分代，但逻辑上依然存在新生代、S区、老年代和Huge区。
 3.我们公司monitor系统对younggc的触发和监控时长是通过什么方式检测到的
   通过调用JMX的方法
 4.G1的内存布局是每个region大小都固定，且在1-32M之间，如果分配一个超过32M的内存对象，该如何分配？
   超过Region一半的对象，一半会直接分配在Huge区，如果一个Huge放不下，就放置多个
 5.G1将Heap分成了多个Region后，在gc时清理跨region的引用对象时怎么办？(参考3.3.1和3.3.4)
   
 6.在并发标记时，如果保证gc线程和用户线程互不干扰(参考3.4.6)
 7.怎样建立可预测停顿模型
 8.G1在gc时为什么要进行3次标记
 9.G1在发生fullgc时，是怎么清理内存的？和普通mirorgc...清理时是不是不区分minorgc
 10.在解决对象消失时为什么CMS采用增量更新，而g1采用原始快照的方式？
 11.G1用过什么策略控制停顿时间的？
    估计类似Netty的NioEventLoop的ioRatio实现
 12.G1如何做到GC时间预测的，是根据什么来预测出停顿时间的？
 13.什么时候出发Ygc、MixedGC和FullGC
 14.和CMS一个问题，GC的FullGC为什么要StopWorld+单线程
 15.JVM参数中，如果开启了G1，默认线程数和默认Region大小是多少
 16.什么场景适合使用G1，以及原因是什么？
    大内存时推荐使用G1

### 3.6 低延迟垃圾回收器，没见过，需要学习一下

### 3.7 如何选择合适的垃圾收集器
  1) Epsilon是什么收集器 

### 3.8 
  1) 晋升老年代的条件是什么？
  2) 
  
####FollowUp
 1.强软弱虚4个引用怎么使用？源码中是如何使用这些引用的？
 2.cms失败后会触发fullgc，那么这时的fullgc用什么gc收集器清理老年代，不还是cms吗？
 3.为什么fullgc会慢，fullgc都做了哪些事情，这些事情分布时间占比大概是多少？
 4.怎么区分新生代和老年代的GCRoot?
